{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[-0.0586, -0.0960, -1.1289],\n         [ 0.7551,  0.5630,  1.7815],\n         [-1.7009, -1.5850, -0.8644]],\n\n        [[ 0.2892,  0.5145,  1.8476],\n         [-1.3496, -2.1752,  2.0551],\n         [ 0.4155,  1.3952, -0.0387]],\n\n        [[-0.5807, -1.4092,  1.7368],\n         [ 1.8485,  1.3379, -0.0839],\n         [ 0.1671,  0.7975,  0.9323]]])\ntensor([[-0.0586, -0.0960, -1.1289,  0.7551,  0.5630,  1.7815, -1.7009, -1.5850,\n         -0.8644],\n        [ 0.2892,  0.5145,  1.8476, -1.3496, -2.1752,  2.0551,  0.4155,  1.3952,\n         -0.0387],\n        [-0.5807, -1.4092,  1.7368,  1.8485,  1.3379, -0.0839,  0.1671,  0.7975,\n          0.9323]])\n"
     ]
    }
   ],
   "source": [
    "N, W, H = (3, 3, 3)\n",
    "x = torch.randn([N,W,H])\n",
    "print(x)\n",
    "x = x.reshape([N, W*H])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[5, 3, 4, 0, 1, 8, 2, 7, 6],\n        [5, 2, 7, 1, 6, 0, 8, 3, 4],\n        [3, 2, 4, 8, 7, 6, 5, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "_, indices = torch.sort(x, descending=True, dim=1)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[5, 3, 4],\n        [5, 2, 7],\n        [3, 2, 4]])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_indices = indices[:, :top_k]\n",
    "print(top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 9])\ntorch.Size([3, 3])\ntensor([[-0.0586, -0.0960, -1.1289,  0.7551,  0.5630,  1.7815, -1.7009, -1.5850,\n         -0.8644],\n        [ 0.2892,  0.5145,  1.8476, -1.3496, -2.1752,  2.0551,  0.4155,  1.3952,\n         -0.0387],\n        [-0.5807, -1.4092,  1.7368,  1.8485,  1.3379, -0.0839,  0.1671,  0.7975,\n          0.9323]])\ntensor([[5, 3, 4],\n        [5, 2, 7],\n        [3, 2, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(top_indices.shape)\n",
    "\n",
    "print(x)\n",
    "print(top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0586, -0.0960, -1.1289,  0.7551,  0.5630,  1.7815, -1.7009, -1.5850,\n         -0.8644],\n        [ 0.2892,  0.5145,  1.8476, -1.3496, -2.1752,  2.0551,  0.4155,  1.3952,\n         -0.0387],\n        [-0.5807, -1.4092,  1.7368,  1.8485,  1.3379, -0.0839,  0.1671,  0.7975,\n          0.9323]])\ntensor([[-0.0586, -0.0960, -1.1289,  0.0000,  0.0000,  0.0000, -1.7009, -1.5850,\n         -0.8644],\n        [ 0.2892,  0.5145,  0.0000, -1.3496, -2.1752,  0.0000,  0.4155,  0.0000,\n         -0.0387],\n        [-0.5807, -1.4092,  0.0000,  0.0000,  0.0000, -0.0839,  0.1671,  0.7975,\n          0.9323]])\n"
     ]
    }
   ],
   "source": [
    "mask = x.clone()\n",
    "for i in range(N):\n",
    "    mask[i, top_indices[i]] = 0\n",
    "\n",
    "print(x)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.2500, 0.7500, 0.2500]]) tensor([[0.7500, 0.7500, 0.2500]])\ntensor([[0.2500, 0.7500],\n        [0.7500, 0.7500],\n        [0.2500, 0.2500]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[0., 0.],\n",
       "          [1., 0.]]]),\n",
       " tensor([[0.2500, 0.7500],\n",
       "         [0.7500, 0.7500],\n",
       "         [0.2500, 0.2500]]))"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "def generate_attentive_mask(attention_map, top_k):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            attention_map   (Tensor) : NxWxH tensor after GAP.\n",
    "            top_k           (Tensor) : Number of candidates of the most intense points.\n",
    "        Output:\n",
    "            mask            (Tensor) : NxWxH tensor for masking attentive regions\n",
    "            coords          (Tensor) : Normalized coordinates(cx, cy) for masked regions\n",
    "    \"\"\"\n",
    "    N, W, H = attention_map.shape\n",
    "    x = attention_map.reshape([N, W *H])\n",
    "\n",
    "    _, indices = torch.sort(x, descending=True, dim=1)\n",
    "\n",
    "    top_indices = indices[:, :top_k]\n",
    "\n",
    "    cell_width, cell_height = 1/W, 1/H\n",
    "\n",
    "    rows, cols = (top_indices//W)/N, (top_indices%W)/N\n",
    "    cx = cell_width/2 + rows*cell_width\n",
    "    cy = cell_height/2 + cols*cell_height\n",
    "    coords = torch.cat((cx, cy), dim=0).T\n",
    "\n",
    "    print(cx, cy)\n",
    "    print(coords)\n",
    "\n",
    "    mask = x.clone()\n",
    "\n",
    "    for i in range(N):\n",
    "        mask[i, top_indices[i]] = 0\n",
    "\n",
    "    mask = mask.reshape([N, W, H])\n",
    "    # print(mask)\n",
    "    mask[mask != 0] = 1\n",
    "\n",
    "    return mask, coords\n",
    "\n",
    "N, W, H = (1, 2,2)\n",
    "attention_map = torch.randn([N,W,H])\n",
    "# print(attention_map)\n",
    "generate_attentive_mask(attention_map, top_k=3)"
   ]
  }
 ]
}