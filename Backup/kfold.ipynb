{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "For K-fold Cross Validation (MosquitoDL)\n",
    "- Split 'Train dataset' in k-folds.\n",
    "    - For each iteration, train with k-1 datasets, and validate with a dataset.\n",
    "    - 1 epoch = 5 fold iteration\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import transforms, datasets\n",
    "from resnet import ResNet\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_scale = 1.15\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1,contrast=0.2,saturation=0.2,hue=0.1),\n",
    "    transforms.RandomAffine(360,scale=[init_scale-0.15, init_scale+0.15]),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.816, 0.744, 0.721],std=[0.146, 0.134, 0.121]),\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"../mosquitoClassification/MosquitoDL/train\", transform=transforms_train)\n",
    "\n",
    "len_fold, len_fold_rest = len(train_dataset)//num_folds, len(train_dataset) % num_folds\n",
    "\n",
    "fold_lengths = [len_fold for x in range(num_folds)]\n",
    "\n",
    "if(len_fold_rest != 0):\n",
    "    fold_lengths.append(len_fold_rest + len_fold)\n",
    "\n",
    "train_dataset = torch.utils.data.random_split(train_dataset, fold_lengths)\n",
    "\n",
    "train_loader = {x: torch.utils.data.DataLoader(train_dataset[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=8)\n",
    "                for x in range(num_folds)}\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\"../mosquitoClassification/MosquitoDL/valid\", transform=transforms_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "\n",
    "numberofclass = 6\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(nn.Module):\n",
    "    def __init__(self, model, stage_names):\n",
    "        super(Wrapper, self).__init__()\n",
    "\n",
    "        self.dict_activation = {}\n",
    "        self.dict_gradients = {}\n",
    "        self.forward_hook_handles = []\n",
    "        self.backward_hook_handles = []\n",
    "\n",
    "        self.net = model\n",
    "        self.stage_names = stage_names\n",
    "        self.num_stages = len(self.stage_names)\n",
    "\n",
    "        def forward_hook_function(name): # Hook function for the forward pass.\n",
    "            def get_class_activation(module, input, output):\n",
    "                self.dict_activation[name] = output.data\n",
    "            return get_class_activation\n",
    "\n",
    "        def backward_hook_function(name): # Hook function for the forward pass.\n",
    "            def get_class_gradient(module, input, output):\n",
    "                self.dict_gradients[name] = output\n",
    "            return get_class_gradient\n",
    "\n",
    "        for L in self.stage_names:\n",
    "            for k, v in self.net.named_modules():\n",
    "                if L in k:\n",
    "                    self.forward_hook_handles.append(v.register_forward_hook(forward_hook_function(L)))\n",
    "                    self.backward_hook_handles.append(v.register_backward_hook(backward_hook_function(L)))\n",
    "                    print(f\"Registered forward/backward hook on \\'{k}\\'\")\n",
    "                    break\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.clear_dict()\n",
    "        return self.net(x)\n",
    "            \n",
    "    def print_current_dicts(self):\n",
    "        for k, v in self.dict_activation.items():\n",
    "            print(\"[FW] Layer:\", k)\n",
    "            print(\"[FW] Shape:\", v.shape)\n",
    "        for k, v in self.dict_gradients.items():\n",
    "            print(\"[BW] Layer:\", k)      \n",
    "            print(\"[BW] Shape:\", v.shape)\n",
    "\n",
    "\n",
    "\n",
    "    def clear_dict(self):\n",
    "        for k, v in self.dict_activation.items():\n",
    "            v = None\n",
    "        for k, v in self.dict_gradients.items():\n",
    "            v = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load pretrained state dict './pretrained/R50_ImageNet_Baseline.pth'\nRegistered forward/backward hook on 'module.layer1'\nRegistered forward/backward hook on 'module.layer2'\nRegistered forward/backward hook on 'module.layer3'\nRegistered forward/backward hook on 'module.layer4'\n"
     ]
    }
   ],
   "source": [
    "model = ResNet('mosquitodl', 50, 6, True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 6)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "pretrained_path = './pretrained/R50_ImageNet_Baseline.pth'\n",
    "\n",
    "if pretrained_path != None:\n",
    "    pretrained_dict = torch.load(pretrained_path)['state_dict']\n",
    "    new_model_dict = model.state_dict()\n",
    "\n",
    "    for k, v in new_model_dict.items():\n",
    "        if 'fc' in k:\n",
    "            continue\n",
    "        else:\n",
    "            new_model_dict[k] = pretrained_dict[k]\n",
    "\n",
    "    model.load_state_dict(new_model_dict)\n",
    "    print(f\"Load pretrained state dict \\'{pretrained_path}\\'\")\n",
    "\n",
    "stage_names = ['layer1','layer2','layer3','layer4']\n",
    "\n",
    "model = Wrapper(model, stage_names)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfold_trainer import train_k_fold, test\n",
    "from kfold_trainer_variants import train_k_fold_MACM, train_k_fold_MCACM\n",
    "save_name = \"./test.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== Current Epoch: 1\n\t - Train/Val Phase ...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-417bedc1ceb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t - Train/Val Phase ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_valid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_valid_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         train_k_fold_MCACM(model, train_loader, optimizer, scheduler, criterion, num_folds, epoch, device, \\\n\u001b[0m\u001b[1;32m     10\u001b[0m             net_type='resnet', k=1, image_priority='A', cut_prob=0, save_path='./batch_samples/', target_mode='label')\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/backup/CutMix-PyTorch/kfold_trainer_variants.py\u001b[0m in \u001b[0;36mtrain_k_fold_MCACM\u001b[0;34m(model, train_loader, optimizer, scheduler, criterion, num_folds, cur_epoch, device, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# print(f\"\\t\\t - Validation: {cur_val_fold}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_val_fold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"==== Current Epoch: {epoch+1}\")\n",
    "\n",
    "    best_model = None\n",
    "    best_test_acc = 0\n",
    "\n",
    "    print(f\"\\t - Train/Val Phase ...\")\n",
    "    model, (epoch_train_loss, epoch_train_acc), (epoch_valid_loss, epoch_valid_acc) = \\\n",
    "        train_k_fold_MCACM(model, train_loader, optimizer, scheduler, criterion, num_folds, epoch, device, \\\n",
    "            net_type='resnet', k=1, image_priority='A', cut_prob=0, save_path='./batch_samples/', target_mode='label')\n",
    "\n",
    "    print(f\"\\t - Epoch training loss : {epoch_train_loss:.4f}\")\n",
    "    print(f\"\\t - Epoch training accuracy : {epoch_train_acc*100:.4f}%\")\n",
    "    print(f\"\\t - Epoch validation loss : {epoch_valid_loss:.4f}\")\n",
    "    print(f\"\\t - Epoch validation accuracy : {epoch_valid_acc*100:.4f}%\")\n",
    "\n",
    "    print(f\"\\t - Test Phase ...\")\n",
    "    model, epoch_test_loss, epoch_test_acc = test(model, test_loader, criterion, device)\n",
    "    print(f\"\\t - Epoch test loss : {epoch_test_loss:.4f}\")\n",
    "    print(f\"\\t - Epoch test accuracy : {epoch_test_acc*100:.4f}%\")\n",
    "\n",
    "    if epoch_test_acc > best_test_acc:\n",
    "        best_test_acc = epoch_test_acc\n",
    "        print(f\"Save best model with test accuracy: {best_test_acc*100:.4f}%\")\n",
    "        torch.save(model.state_dict(), save_name)\n"
   ]
  }
 ]
}